{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efc342ca",
   "metadata": {},
   "source": [
    "This is a slightly edited version of the kindly shared code from https://github.com/amunategui/Chatbot-Conversations/blob/master/Chatbot-Conversations.ipynb which is discussed in some detail in https://www.springml.com/blog/building-intents-customer-service-transcripts/.\n",
    "\n",
    "The objective is to replicate some of these techniques in a later version in R, with parallelization, and compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de2ecd83-ec47-46cd-a0c4-490825e50852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys, os, re, itertools, collections, string, time\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "672e9d41-86f9-4be2-bc71-03f060c321b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\013769\\AppData\\Local\\Temp\\1/ipykernel_21724/303704451.py:19: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  complaints_df_raw['Consumer complaint narrative'] = complaints_df_raw['Consumer complaint narrative'].str.replace('\\W', ' ')\n"
     ]
    }
   ],
   "source": [
    "# https://catalog.data.gov/dataset/consumer-complaint-database \n",
    "complaints_df_raw = pd.read_csv(\"complaints.csv\", \n",
    "                usecols=('Product','Consumer complaint narrative', 'Sub-issue'),\n",
    "                dtype={'consumer_complaint_narrative': object})\n",
    "# Only interested in data with consumer complaints\n",
    "complaints_df_raw=complaints_df_raw[complaints_df_raw['Consumer complaint narrative'].notnull()]\n",
    "complaints_df_raw=complaints_df_raw[complaints_df_raw['Product'].notnull()]\n",
    "\n",
    "# remove XXXX from narratives\n",
    "complaints_df_raw['Consumer complaint narrative'] =  complaints_df_raw['Consumer complaint narrative'].replace({'X':''}, regex=True)\n",
    "\n",
    "# always seed your random generators for reporducilibity \n",
    "complaints_df_raw = complaints_df_raw.sample(200000, replace=False, random_state=1)\n",
    "\n",
    "# basic sentence prep\n",
    "# set to lower\n",
    "complaints_df_raw['Consumer complaint narrative'] = complaints_df_raw['Consumer complaint narrative'].str.lower()\n",
    "# remove special characters\n",
    "complaints_df_raw['Consumer complaint narrative'] = complaints_df_raw['Consumer complaint narrative'].str.replace('\\W', ' ')\n",
    "\n",
    "# remove elements with no text\n",
    "complaints_df_raw= complaints_df_raw[complaints_df_raw['Consumer complaint narrative'] != '']\n",
    "\n",
    "# any dups\n",
    "complaints_df_raw = complaints_df_raw.drop_duplicates(subset=['Consumer complaint narrative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45e43446-fefe-41a4-92a7-a102a840f2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430854</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Their investigation did not fix an error on yo...</td>\n",
       "      <td>experian is reporting incorrectly that i am 15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200159</th>\n",
       "      <td>Payday loan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>on     i received an alert that i have a new c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96476</th>\n",
       "      <td>Credit reporting, credit repair services, or o...</td>\n",
       "      <td>Account status incorrect</td>\n",
       "      <td>transunion llc       pa   re   letter to remov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150206</th>\n",
       "      <td>Debt collection</td>\n",
       "      <td>Didn't receive notice of right to dispute</td>\n",
       "      <td>thank you for your recent communication wherei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759119</th>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Information is not mine</td>\n",
       "      <td>i am disputing the  hard inquiries that are on...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Product  \\\n",
       "430854   Credit reporting, credit repair services, or o...   \n",
       "200159                                         Payday loan   \n",
       "96476    Credit reporting, credit repair services, or o...   \n",
       "2150206                                    Debt collection   \n",
       "759119                                    Credit reporting   \n",
       "\n",
       "                                                 Sub-issue  \\\n",
       "430854   Their investigation did not fix an error on yo...   \n",
       "200159                                                 NaN   \n",
       "96476                             Account status incorrect   \n",
       "2150206          Didn't receive notice of right to dispute   \n",
       "759119                             Information is not mine   \n",
       "\n",
       "                              Consumer complaint narrative  \n",
       "430854   experian is reporting incorrectly that i am 15...  \n",
       "200159   on     i received an alert that i have a new c...  \n",
       "96476    transunion llc       pa   re   letter to remov...  \n",
       "2150206  thank you for your recent communication wherei...  \n",
       "759119   i am disputing the  hard inquiries that are on...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complaints_df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ea1578-efda-432c-b82f-fda3b35fb972",
   "metadata": {},
   "source": [
    "# Clean Up Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f26888-57ce-40fa-ba9d-14728246ae1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_df = complaints_df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f971e8-e1e2-4c69-9f69-38ad78ed2901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188091, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_similarity=complaints_df['Consumer complaint narrative'].str.split(' ').map(Counter)\n",
    "word_similarity_ratio = []\n",
    "complaints_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68b15108-34af-4b8e-bc6d-22573b7c10ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\013769\\AppData\\Local\\Temp\\1/ipykernel_21724/4135827764.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  word_similarity_ratio.append(np.sum([x[1] for x in wu.items()])/np.float(len(wu)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    188091.000000\n",
       "mean          2.125075\n",
       "std           0.945147\n",
       "min           1.000000\n",
       "25%           1.621951\n",
       "50%           1.972477\n",
       "75%           2.420455\n",
       "max          52.850000\n",
       "Name: narrative_similarity_ratio, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for wu in word_similarity:\n",
    "    word_similarity_ratio.append(np.sum([x[1] for x in wu.items()])/np.float(len(wu)))\n",
    "    \n",
    "complaints_df['narrative_similarity_ratio'] = word_similarity_ratio\n",
    "complaints_df['narrative_similarity_ratio'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dbecf30-c20b-4667-95af-a6e88204189f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57501, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# thin out some entries that contain too much duplicated lines within\n",
    "complaints_df = complaints_df[complaints_df['narrative_similarity_ratio'] <= 1.7]\n",
    "complaints_df.reset_index(drop=True,inplace=True)\n",
    "complaints_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40ac3fde-cd97-4357-8fdb-b13e241bb9e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['was put on a nine month rehab program  completed it and was charged   13000 00  additional interest along with a   6000 00  fee after completion and they kept taking off the once one driven repayment plan before the renewal one year time was up and was not allowed to regain it along with being told call the deparrment of education to ask them to take off the additional interest  asked numerous times to send me the forms in the mail to reinstate for income driven repayment plan and never received anything  then started getting 10 robo calls a day from unknown numbers along with navient     calling and harrassing me with nonstop daily calls leaving message or voicemail with someone talking so fast noone could understand  this is ridiculous and illegal and harassment',\n",
       " 'all attempts to settle the account and make payment are attached below  the company chrysler capital failed to respond to all document presentments as well as has taken the personal property and has kept the financial instrument ',\n",
       " 'on      i sent a letter to experian and  asking to provide me with documents that they were verifying as accurate on several accts  on    it was submitted into dispute and on    was once again verified as accurate without providing any information on how they verified this information  one of the account had been sold to a different source a couple years ago and i was never provided that information yet still appears on my credit profile  i sent a letter via certified mail stating to please provide me with mov or i would be contacting cfpb',\n",
       " 'according to 15usc 1681 under the exclusion section 2a1 the fair credit act states the company must show proof of ownership to debt i asked for original paper work to accorded debt in   2021  i have not received any reply nor have they took off this debt that i do not own ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(complaints_df['Consumer complaint narrative'])[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010bc448-6379-411a-8bab-f2f3731c29e7",
   "metadata": {},
   "source": [
    "# Get Key Verbs And Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0be3329-7aa2-4dc8-b3e7-f89bd32263bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find most common verbs and measure coverage \n",
    "import spacy\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "#nlp = spacy.load('en')\n",
    "\n",
    "# just load what we need to avoid taxing memory\n",
    "nlp = spacy.load('en_core_web_sm') # you can install 'en_core_web_sm' with this command in Anaconda Prompt (for Windows) - python -m spacy download en_core_web_sm - see https://stackoverflow.com/a/57989297/4856426"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db5f7742-f3a0-4631-b287-014e1078422a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create one big blob of text to process things a bit faster\n",
    "blob_complaints = ''.join(list(complaints_df['Consumer complaint narrative']))\n",
    "\n",
    "# Max text of length of 1000000\n",
    "n = 900000\n",
    "blog_chunks = [blob_complaints[i:i+n] for i in range(0, len(blob_complaints), n)]\n",
    "len(blog_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b7e7b06-cede-4935-9d9e-243c36a7a10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x1d10d147940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83c4b44e-6a3d-46f8-9627-6a71c0a402e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "19\n",
      "18\n",
      "17\n",
      "16\n",
      "15\n",
      "14\n",
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "just_verbs = []\n",
    "just_nouns = []\n",
    "counter_=len(blog_chunks)\n",
    "for sentence in blog_chunks:\n",
    "    counter_ -= 1\n",
    "    if (counter_ % 10 == 0): print(counter_)\n",
    "    print(counter_)\n",
    "    # doc = nlp(sentence.decode('utf-8'))\n",
    "    doc = nlp(sentence)\n",
    "    temp_verb = []\n",
    "    temp_noun = []\n",
    "    for token in doc: \n",
    "        if (token.pos_ == u'VERB'): \n",
    "            temp_verb.append(token.text)\n",
    "        if (token.pos_ == u'NOUN'):\n",
    "            temp_noun.append(token.text)\n",
    "            \n",
    "\n",
    "    # just_verbs.append(' '.join(temp_verb).encode('utf-8'))\n",
    "    just_verbs.append(' '.join(temp_verb))\n",
    "    # just_nouns.append(' '.join(temp_noun).encode('utf-8'))\n",
    "    just_nouns.append(' '.join(temp_noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bf9af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['put',\n",
       " 'completed',\n",
       " 'charged',\n",
       " 'kept',\n",
       " 'taking',\n",
       " 'driven',\n",
       " 'allowed',\n",
       " 'regain',\n",
       " 'told',\n",
       " 'call']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_verbs[0].split()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fa27059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'interest',\n",
       " 'fee',\n",
       " 'completion',\n",
       " 'repayment',\n",
       " 'plan',\n",
       " 'renewal',\n",
       " 'year',\n",
       " 'time',\n",
       " 'deparrment']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "just_nouns[0].split()[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceabc77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count just_verbs: 21\n",
      "count just_nouns: 21\n"
     ]
    }
   ],
   "source": [
    "print('count just_verbs: %i' % len(just_verbs))\n",
    "print('count just_nouns: %i' % len(just_nouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6d7d3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle both objects so you don't have to re-run spacy \n",
    "import pickle\n",
    "pickle_file = \"verbs_nouns.p\"\n",
    "\n",
    "overwrite_old_pickle = True\n",
    "if overwrite_old_pickle:\n",
    "    with open(pickle_file, \"wb\") as f:\n",
    "        pickle.dump([just_verbs, just_nouns], f)\n",
    "    \n",
    "# read in saved pickle\n",
    "with open(pickle_file, \"rb\") as f:\n",
    "    backup_pos = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8927b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_verbs = backup_pos[0]\n",
    "len(all_verbs)\n",
    "\n",
    "# append all verbs together so we can run frequency counts\n",
    "verbs = []\n",
    "for verb_set in all_verbs:\n",
    "    verbs.append(verb_set.split())\n",
    "    #verbs = [verb for verb in verb_set[0].split()]\n",
    "\n",
    "len(verbs)\n",
    "verbs_master = [val for sublist in verbs for val in sublist]\n",
    "len(verbs_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1959379f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verb</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>have</td>\n",
       "      <td>15375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sent</td>\n",
       "      <td>8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>received</td>\n",
       "      <td>8108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>reporting</td>\n",
       "      <td>6916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>removed</td>\n",
       "      <td>6398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paid</td>\n",
       "      <td>6332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>had</td>\n",
       "      <td>6254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>get</td>\n",
       "      <td>6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>remove</td>\n",
       "      <td>6062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>called</td>\n",
       "      <td>5429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>told</td>\n",
       "      <td>4837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>reported</td>\n",
       "      <td>4374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>made</td>\n",
       "      <td>4291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pay</td>\n",
       "      <td>4091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>contacted</td>\n",
       "      <td>3889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>do</td>\n",
       "      <td>3719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>disputed</td>\n",
       "      <td>3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>trying</td>\n",
       "      <td>3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>tried</td>\n",
       "      <td>3224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>call</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         verb  count\n",
       "0        have  15375\n",
       "1        sent   8713\n",
       "2    received   8108\n",
       "3   reporting   6916\n",
       "4     removed   6398\n",
       "5        paid   6332\n",
       "6         had   6254\n",
       "7         get   6140\n",
       "8      remove   6062\n",
       "9      called   5429\n",
       "10       told   4837\n",
       "11   reported   4374\n",
       "12       made   4291\n",
       "13        pay   4091\n",
       "14  contacted   3889\n",
       "15         do   3719\n",
       "16   disputed   3450\n",
       "17     trying   3412\n",
       "18      tried   3224\n",
       "19       call   3203"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is your upper and lower cut offs?\n",
    "from collections import Counter\n",
    "verbs_df = pd.DataFrame(Counter([verb for verb in verbs_master]).most_common(), columns = ['verb', 'count'])\n",
    "verbs_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba31bba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verbs_df[verbs_df['count'] > 1000])\n",
    "verbs_df = verbs_df[verbs_df['count'] > 1000]\n",
    "len(verbs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6fa6c8",
   "metadata": {},
   "source": [
    "# Sorting Out Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb423efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "715210"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nouns = backup_pos[1]\n",
    "\n",
    "# append all verbs together so we can run frequency counts\n",
    "nouns = []\n",
    "for noun_set in all_nouns:\n",
    "    nouns.append(noun_set.split())\n",
    "\n",
    "nouns_master = [val for sublist in nouns for val in sublist]\n",
    "len(nouns_master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ed8842f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>credit</td>\n",
       "      <td>48843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>account</td>\n",
       "      <td>28241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>report</td>\n",
       "      <td>23484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>information</td>\n",
       "      <td>15400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>debt</td>\n",
       "      <td>14560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          noun  count\n",
       "0       credit  48843\n",
       "1      account  28241\n",
       "2       report  23484\n",
       "3  information  15400\n",
       "4         debt  14560"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is your upper and lower cut offs?\n",
    "from collections import Counter\n",
    "nouns_df = pd.DataFrame(Counter([noun for noun in nouns_master]).most_common(), columns = ['noun', 'count'])\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac8faf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nouns_df[nouns_df['count'] > 1000])\n",
    "nouns_df = nouns_df[nouns_df['count'] > 1000]\n",
    "len(nouns_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55011bb6",
   "metadata": {},
   "source": [
    "### Binarize DataFrame With Official Verb & Noun List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff5a5873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "40000\n",
      "30000\n",
      "20000\n",
      "10000\n",
      "0\n",
      "length: 57501\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(57501, 247)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new data frame with key verbs and nouns as features\n",
    "key_words = list(nouns_df['noun']) + list(verbs_df['verb'])\n",
    "row_bools = []\n",
    "counter_ = len(complaints_df['Consumer complaint narrative'])\n",
    "for sentence in complaints_df['Consumer complaint narrative']:\n",
    "    counter_ -= 1\n",
    "    if (counter_ % 10000 == 0): print(counter_)\n",
    "    row_bool = []\n",
    "    words = sentence.split()\n",
    "    for kw in key_words:\n",
    "        row_bool.append(kw in words)\n",
    "    row_bools.append(row_bool)\n",
    "    \n",
    "print('length:', len(row_bools))\n",
    "row_bools = pd.DataFrame(row_bools, columns=key_words)    \n",
    "row_bools = row_bools.astype(int)\n",
    "row_bools.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b43bd5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit</th>\n",
       "      <th>account</th>\n",
       "      <th>report</th>\n",
       "      <th>information</th>\n",
       "      <th>debt</th>\n",
       "      <th>company</th>\n",
       "      <th>accounts</th>\n",
       "      <th>loan</th>\n",
       "      <th>payment</th>\n",
       "      <th>card</th>\n",
       "      <th>...</th>\n",
       "      <th>shows</th>\n",
       "      <th>having</th>\n",
       "      <th>sold</th>\n",
       "      <th>was</th>\n",
       "      <th>sending</th>\n",
       "      <th>certified</th>\n",
       "      <th>according</th>\n",
       "      <th>informed</th>\n",
       "      <th>respond</th>\n",
       "      <th>needs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit  account  report  information  debt  company  accounts  loan  \\\n",
       "0       0        0       0            0     0        0         0     0   \n",
       "1       0        1       0            0     0        1         0     0   \n",
       "2       1        1       0            1     0        0         0     0   \n",
       "3       1        0       0            0     1        1         0     0   \n",
       "4       0        1       0            0     1        0         0     1   \n",
       "\n",
       "   payment  card  ...  shows  having  sold  was  sending  certified  \\\n",
       "0        0     0  ...      0       0     0    1        0          0   \n",
       "1        1     0  ...      0       0     0    0        0          0   \n",
       "2        0     0  ...      0       0     1    1        0          1   \n",
       "3        0     0  ...      0       0     0    0        0          0   \n",
       "4        1     0  ...      0       0     0    1        0          0   \n",
       "\n",
       "   according  informed  respond  needs  \n",
       "0          0         0        0      0  \n",
       "1          0         0        1      0  \n",
       "2          0         0        0      0  \n",
       "3          1         0        0      0  \n",
       "4          0         0        0      0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_bools.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c1a2666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit</th>\n",
       "      <th>account</th>\n",
       "      <th>report</th>\n",
       "      <th>information</th>\n",
       "      <th>debt</th>\n",
       "      <th>company</th>\n",
       "      <th>accounts</th>\n",
       "      <th>loan</th>\n",
       "      <th>payment</th>\n",
       "      <th>card</th>\n",
       "      <th>...</th>\n",
       "      <th>shows</th>\n",
       "      <th>having</th>\n",
       "      <th>sold</th>\n",
       "      <th>was</th>\n",
       "      <th>sending</th>\n",
       "      <th>certified</th>\n",
       "      <th>according</th>\n",
       "      <th>informed</th>\n",
       "      <th>respond</th>\n",
       "      <th>needs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57496</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57498</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57499</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57500</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 247 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       credit  account  report  information  debt  company  accounts  loan  \\\n",
       "57496       0        1       0            0     1        0         0     0   \n",
       "57497       0        0       1            0     0        0         0     0   \n",
       "57498       0        1       0            1     0        0         0     0   \n",
       "57499       1        0       1            0     0        1         0     0   \n",
       "57500       1        1       1            1     0        1         0     0   \n",
       "\n",
       "       payment  card  ...  shows  having  sold  was  sending  certified  \\\n",
       "57496        0     0  ...      0       0     0    0        0          0   \n",
       "57497        0     0  ...      0       0     0    0        0          0   \n",
       "57498        0     1  ...      0       0     0    1        0          0   \n",
       "57499        0     0  ...      0       0     0    0        0          0   \n",
       "57500        0     0  ...      0       0     0    1        0          0   \n",
       "\n",
       "       according  informed  respond  needs  \n",
       "57496          0         0        0      0  \n",
       "57497          0         0        0      0  \n",
       "57498          0         0        0      0  \n",
       "57499          0         0        0      0  \n",
       "57500          0         0        1      0  \n",
       "\n",
       "[5 rows x 247 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_bools.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e95631",
   "metadata": {},
   "source": [
    "### Cluster of popular sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84a980d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3501\n",
       "5     2703\n",
       "27    2418\n",
       "41    2240\n",
       "49    2138\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "TOTAL_CLUSTERS = 50\n",
    "\n",
    "# Number of clusters\n",
    "kmeans = KMeans(n_clusters=TOTAL_CLUSTERS)\n",
    "# Fitting the input data\n",
    "kmeans = kmeans.fit(row_bools)\n",
    "# Getting the cluster labels\n",
    "labels = kmeans.predict(row_bools)\n",
    "\n",
    "# add cluster back to data frame \n",
    "row_bools['cluster'] = labels\n",
    "\n",
    "row_bools['cluster'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "baf19884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     3501\n",
       "5     2703\n",
       "27    2418\n",
       "41    2240\n",
       "49    2138\n",
       "Name: cluster, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_bools['cluster'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3fc82e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "data cluster shape: 3501\n",
      "Cluster: 1\n",
      "data cluster shape: 1494\n",
      "Cluster: 2\n",
      "data cluster shape: 1494\n",
      "Cluster: 3\n",
      "data cluster shape: 805\n",
      "Cluster: 4\n",
      "data cluster shape: 1026\n",
      "Cluster: 5\n",
      "data cluster shape: 2703\n",
      "Cluster: 6\n",
      "data cluster shape: 807\n",
      "Cluster: 7\n",
      "data cluster shape: 1106\n",
      "Cluster: 8\n",
      "data cluster shape: 654\n",
      "Cluster: 9\n",
      "data cluster shape: 77\n",
      "Cluster: 10\n",
      "data cluster shape: 1299\n",
      "Cluster: 11\n",
      "data cluster shape: 1478\n",
      "Cluster: 12\n",
      "data cluster shape: 1149\n",
      "Cluster: 13\n",
      "data cluster shape: 1017\n",
      "Cluster: 14\n",
      "data cluster shape: 920\n",
      "Cluster: 15\n",
      "data cluster shape: 1364\n",
      "Cluster: 16\n",
      "data cluster shape: 114\n",
      "Cluster: 17\n",
      "data cluster shape: 819\n",
      "Cluster: 18\n",
      "data cluster shape: 809\n",
      "Cluster: 19\n",
      "data cluster shape: 942\n",
      "Cluster: 20\n",
      "data cluster shape: 1198\n",
      "Cluster: 21\n",
      "data cluster shape: 401\n",
      "Cluster: 22\n",
      "data cluster shape: 1751\n",
      "Cluster: 23\n",
      "data cluster shape: 1881\n",
      "Cluster: 24\n",
      "data cluster shape: 1375\n",
      "Cluster: 25\n",
      "data cluster shape: 131\n",
      "Cluster: 26\n",
      "data cluster shape: 37\n",
      "Cluster: 27\n",
      "data cluster shape: 2418\n",
      "Cluster: 28\n",
      "data cluster shape: 891\n",
      "Cluster: 29\n",
      "data cluster shape: 2002\n",
      "Cluster: 30\n",
      "data cluster shape: 1307\n",
      "Cluster: 31\n",
      "data cluster shape: 173\n",
      "Cluster: 32\n",
      "data cluster shape: 1276\n",
      "Cluster: 33\n",
      "data cluster shape: 1658\n",
      "Cluster: 34\n",
      "data cluster shape: 1437\n",
      "Cluster: 35\n",
      "data cluster shape: 40\n",
      "Cluster: 36\n",
      "data cluster shape: 1275\n",
      "Cluster: 37\n",
      "data cluster shape: 1091\n",
      "Cluster: 38\n",
      "data cluster shape: 1355\n",
      "Cluster: 39\n",
      "data cluster shape: 1022\n",
      "Cluster: 40\n",
      "data cluster shape: 31\n",
      "Cluster: 41\n",
      "data cluster shape: 2240\n",
      "Cluster: 42\n",
      "data cluster shape: 1861\n",
      "Cluster: 43\n",
      "data cluster shape: 1401\n",
      "Cluster: 44\n",
      "data cluster shape: 959\n",
      "Cluster: 45\n",
      "data cluster shape: 827\n",
      "Cluster: 46\n",
      "data cluster shape: 653\n",
      "Cluster: 47\n",
      "data cluster shape: 801\n",
      "Cluster: 48\n",
      "data cluster shape: 293\n",
      "Cluster: 49\n",
      "data cluster shape: 2138\n"
     ]
    }
   ],
   "source": [
    "# add cluster number back to orginal corpus\n",
    "complaints_df['Cluster'] = labels\n",
    "# import sys\n",
    "# reload(sys)\n",
    "# sys.setdefaultencoding('utf8')\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import nltk\n",
    "# nltk.download('punkt') # if you get NLTK Resource punkt not found error - https://www.tutorialexample.com/fix-nltk-resource-punkt-not-found-nltk-tutorial/ - only need to download once\n",
    "from nltk.util import ngrams\n",
    "\n",
    "unique_complaints_2grams = []\n",
    "unique_complaints_3grams = []\n",
    "unique_complaints_4grams = []\n",
    "unique_complaints_5grams = []\n",
    "unique_complaints_6grams = []\n",
    "# loop through each cluster\n",
    "for cluster_to_search in range(min(row_bools['cluster']), max(row_bools['cluster'])+1):\n",
    "    # cluster-level research\n",
    "    print('Cluster: %i' % cluster_to_search)\n",
    "    df_tmp = complaints_df[complaints_df['Cluster']==cluster_to_search].copy()\n",
    "    print('data cluster shape: %s' % len(df_tmp))\n",
    "    \n",
    "    bigrams = []\n",
    "    trigrams = []\n",
    "    fourgrams = []\n",
    "    fivegrams = []\n",
    "    sixgrams = []\n",
    "    \n",
    "    for index, row in df_tmp.iterrows(): \n",
    "        # token = nltk.word_tokenize(row['Consumer complaint narrative'].decode('utf-8'))\n",
    "        token = nltk.word_tokenize(row['Consumer complaint narrative'])\n",
    "        bigrams.append([' '.join(pair) for pair in list(ngrams(token,2)) if len(set(pair))==2])\n",
    "        trigrams.append([' '.join(pair) for pair in list(ngrams(token,3)) if len(set(pair))==3])\n",
    "        fourgrams.append([' '.join(pair) for pair in list(ngrams(token,4)) if len(set(pair))==4])\n",
    "        fivegrams.append([' '.join(pair) for pair in list(ngrams(token,5)) if len(set(pair))==5])\n",
    "        sixgrams.append([' '.join(pair) for pair in list(ngrams(token,6)) if len(set(pair))==6])\n",
    "        \n",
    "    bigrams = [val for sublist in bigrams for val in sublist]\n",
    "    trigrams = [val for sublist in trigrams for val in sublist]\n",
    "    fourgrams = [val for sublist in fourgrams for val in sublist]\n",
    "    fivegrams = [val for sublist in fivegrams for val in sublist]\n",
    "    sixgrams = [val for sublist in sixgrams for val in sublist]\n",
    "    \n",
    "    # find top x most popular grams per size\n",
    "    # 2 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in bigrams]).most_common(50), columns=['bigrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_2grams.append(freqx)\n",
    "    # 3 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in trigrams]).most_common(50), columns=['trigrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_3grams.append(freqx)\n",
    "    # 4 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in fourgrams]).most_common(50), columns=['fourgrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_4grams.append(freqx)\n",
    "    # 5 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in fivegrams]).most_common(50), columns=['fivegrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_5grams.append(freqx)\n",
    "    # 6 bigrams\n",
    "    freqx = pd.DataFrame(Counter([noun for noun in sixgrams]).most_common(50), columns=['sixgrams','frequency'])\n",
    "    freqx['Cluster'] = cluster_to_search\n",
    "    unique_complaints_6grams.append(freqx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cbcbd178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fourgrams</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>my credit profile is</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>credit profile is inaccurate</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>profile is inaccurate which</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>inaccurate which is not</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>which is not fair</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       fourgrams  frequency  Cluster\n",
       "10          my credit profile is         14        0\n",
       "11  credit profile is inaccurate         14        0\n",
       "12   profile is inaccurate which         14        0\n",
       "13       inaccurate which is not         14        0\n",
       "14             which is not fair         14        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(unique_complaints_4grams)\n",
    "# freqx = pd.DataFrame(Counter([noun for noun in fourgrams]).most_common(50), columns=['fourgrams','frequency'])\n",
    "df = df.drop_duplicates(subset=['fourgrams'], keep=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f5ff061",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sixgrams</th>\n",
       "      <th>frequency</th>\n",
       "      <th>Cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my credit profile is inaccurate which</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inaccurate which is not fair to</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>which is not fair to me</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is not fair to me please</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>not fair to me please investigate</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>that i have no knowledge of</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>from my credit report i have</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>i have not applied for any</td>\n",
       "      <td>14</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>my credit report and i have</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>my credit report that i have</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1488 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sixgrams  frequency  Cluster\n",
       "0   my credit profile is inaccurate which         14        0\n",
       "1         inaccurate which is not fair to         14        0\n",
       "2                 which is not fair to me         14        0\n",
       "3                is not fair to me please         14        0\n",
       "4       not fair to me please investigate         14        0\n",
       "..                                    ...        ...      ...\n",
       "19            that i have no knowledge of         12       49\n",
       "17           from my credit report i have         13       49\n",
       "14             i have not applied for any         14       49\n",
       "12            my credit report and i have         15       49\n",
       "7            my credit report that i have         18       49\n",
       "\n",
       "[1488 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find top x most popular grams per size\n",
    "see_grams = 6\n",
    "\n",
    "\n",
    "if see_grams==2:\n",
    "    df = pd.concat(unique_complaints_2grams)\n",
    "    df = df.drop_duplicates(subset=['bigrams'], keep=False)\n",
    "elif see_grams==3:\n",
    "    df = pd.concat(unique_complaints_3grams)\n",
    "    df = df.drop_duplicates(subset=['trigrams'], keep=False)\n",
    "elif see_grams==4:\n",
    "    df = pd.concat(unique_complaints_4grams)\n",
    "    df = df.drop_duplicates(subset=['fourgrams'], keep=False)\n",
    "elif see_grams==5:\n",
    "    df = pd.concat(unique_complaints_5grams)\n",
    "    df = df.drop_duplicates(subset=['fivegrams'], keep=False)\n",
    "elif see_grams==6:\n",
    "    df = pd.concat(unique_complaints_6grams)\n",
    "    df = df.drop_duplicates(subset=['sixgrams'], keep=False)\n",
    " \n",
    "df = df.sort_values('Cluster')\n",
    "df[df['frequency'] > 10]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c308cb",
   "metadata": {},
   "source": [
    "### Tie It Back To Complaint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a942c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   is attempting to collect a debt from  that was discharged thru bankrutpcy  plus on top of that i never received any information about this debt before it hit my report  i would of told them it was no longer owed  thirdlly the original debt was in my mother  s name   \n",
      "------\n",
      "    is attempting to collect a debt from me that is not owed  they have not submitted any validation or proof of me having a writing contract with      and myself \n",
      "------\n",
      "multiple calls between  and current from different numbers from portfolio recovery  told every single time not to call but to contact by mail  portfolio recovery has also called family members and told them they were attempting to collect a debt from me \n",
      "------\n",
      "there is a company attempting to collect a debt from me  but they keep changing the dates as to when the debt was opened in an attempt to never have the debt removed from my credit report  they will pull the debt from my credit and then replace it with a new date that it was opened \n",
      "------\n",
      "diversified has called my office on multiple occasions from different numbers attempting to collect a debt from someone not associated with this office or myself      we  ve asked them to stop calling but they continue and i feel as if they are violating the fdcpa    can you please assist \n",
      "------\n",
      " company is attempting to collect a debt from me which was paid entirely by the insurance company  and i am only obligated for co payments\n",
      "------\n",
      "commonwealth financial system is attempting to collect a debt from 2014 for a medical bill in which i was on  that covered everything  the collection agency comes years down the line  without proper notice  and places on my credit report    because they apparently could not have billed the insurance company timely it is not my responsibility \n",
      "------\n",
      "this company northwood asset management has repeatedly contacted me and other 3rd party persons not associated with the person they attempting to collect a debt from  when asked to stop and told they can not call us they have threatened and used obscene language and threatened us  when told this is not the number to contact said debtor they insist we must give them information about us and the person they are attempting to contact \n",
      "------\n",
      "i am dealing with the collection agency synergetic communication   inc  i am questioning how legitimate this company is for several reasons  they do not show up as the creditor on my credit report  and they are unlawfully attempting to collect a debt from me by violating several fdcpa laws  they have contacted me before  my time zone and have also called me several times within one hour  they have also never sent me a debt validation letter to make me aware they are the collection agency assigned and to advise me of my rights to dispute the validity of the debt \n",
      "------\n",
      "convergent outsourcing is attempting to collect a debt from   in the amount of   4500 00   this account was handled with  back in 2018 when i first noticed the debt  all appropriate fraud paperwork and investigations were handled at that time  a police report was submitted as well   this account is no longer associated with me legally  \n",
      "------\n",
      "the alleged debt account that was reported to all three credit bureaus is no longer on my credit report and its currently updated right now and i don t know where the alleged debt has come from  i have paid the balance in full on my behalf from what i know of  according to your information that you have gathered  i am a victim of identity theft and i am currently serving notice to this collection agency that is attempting to collect a debt from the original creditor which is i     and i do not validate this debt \n",
      "------\n",
      "ive tried calling this company multiple times about the fraudulent collections they have on my credit report  they keep saying that theyre attempting to collect a debt from a apartment complex ive never lived at in my life  ive sent in the information that was requested my identification official police report and federal trade commission report   theyre still falsifying that the account belongs to me and hanging up in my face  i tried reaching out to the apartments but now there under new management and i wonder why  this is by far the worst experience ive encountered with a company in my   years of living \n",
      "------\n",
      "portfolio recovery has been attempting to collect a debt from me that i do not owe  i have provided proof from the original creditor      that this debt is fraudulent  and in fact does not belong to me \n",
      "------\n",
      "i c  system  inc is attempting to collect a debt from   for   1100 00   i lost my job and could not continue to pay as my family became   ive just been awarded rapid rehousing and have saved up   400 00  to settle the debt  i have not been able to reach the company in regards to settling  i am in need of financial assistance \n",
      "------\n",
      "the collection agency ic systems is attempting to collect a debt from me on behalf of  for unreturned cable equipment  firstly   has confirmed that i did return the equipment and owe them nothing  additionally   has told me that ic system is no longer an authorized collecter for   and is in fact harassing  customers \n",
      "------\n",
      "diversified consultants   inc is attempting to collect a debt from me in the amount of   1100 00  which i am not responsible for and is reporting this fraudulent debt to the credit bureaus in my name  i have been contacting the company since   2019 and requesting that they remove this account from my credit reports as it is fraudulent but they refuse  i received a letter from them on   2019 stating that will not stop reporting this debt \n",
      "------\n",
      "wakefield and associates are attempting to collect a debt from me claiming that i owe   290 00  to the      i don t owe anything to that medical facility as i ve never been a patient there \n",
      "------\n"
     ]
    }
   ],
   "source": [
    "# tie it back to look into a couple of actual complaints\n",
    "keywords = \"attempting to collect a debt from\"\n",
    " \n",
    "for index, row in complaints_df.iterrows():\n",
    "    txt = row['Consumer complaint narrative'] \n",
    "    if (keywords in txt):\n",
    "        print(txt)\n",
    "        print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed0616",
   "metadata": {},
   "source": [
    "# Jasen's scratchpad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a15f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Cluster.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
